{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28963e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['test']\n",
    "collection = db['test']\n",
    "if isinstance(scraped_data, list) and scraped_data:\n",
    "    result = collection.insert_many(scraped_data)\n",
    "else:\n",
    "    print(\"scraped_data is not a list or is empty.\")\n",
    "\n",
    "# Fetch data\n",
    "data = list(collection.find({\"cuisine\": \"Asian\"}))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert ratings and number of ratings to numeric values\n",
    "df['num_ratings'] = pd.to_numeric(df['num_ratings'], errors='coerce')\n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "\n",
    "# Calculate statistics\n",
    "statistics = df.groupby('cuisine').agg({\n",
    "    'num_ratings': ['count', 'quantile', lambda x: x.quantile(0.75)],\n",
    "    'rating': ['mean', 'quantile', lambda x: x.quantile(0.75)]\n",
    "}).rename(columns={'<lambda_0>': '75th percentile', 'quantile': '50th percentile'})\n",
    "\n",
    "# Output results\n",
    "print(statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to MongoDB and access the database and collection\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['tdr_grubhub']\n",
    "collection = db['grubhub_restaurant_urls']\n",
    "\n",
    "# Export data from MongoDB to a Pandas DataFrame\n",
    "df = pd.DataFrame(list(collection.find()))\n",
    "\n",
    "# Pandas Functions for Cleaning and Pre-processing Data\n",
    "# 1. df.dropna() - Remove missing values.\n",
    "# 2. df.fillna() - Fill missing values.\n",
    "# 3. df.astype() - Cast a pandas object to a specified dtype.\n",
    "# 4. df.replace() - Replace values given in 'to_replace' with 'value'.\n",
    "# 5. pd.to_datetime() - Convert argument to datetime.\n",
    "# 6. df.drop_duplicates() - Remove duplicate rows.\n",
    "\n",
    "# Clean and preprocess the data\n",
    "# Convert 'impression_rank' and 'rating' to numeric, setting errors='coerce' will set non-convertible values to NaN\n",
    "df['impression_rank'] = pd.to_numeric(df['impression_rank'], errors='coerce')\n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "\n",
    "# (0) Distribution of Impression Rank\n",
    "impression_rank_percentiles = df['impression_rank'].dropna().quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# (1) Distribution of Ratings\n",
    "ratings_percentiles = df['rating'].dropna().quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# # (2) Total number of rows with scrape attempted is true vs. false\n",
    "# scrape_attempted_counts = df['scrape_attempted'].value_counts()\n",
    "\n",
    "# # Check if 'True' exists in the Series and calculate the percentage\n",
    "# if True in scrape_attempted_counts:\n",
    "#     scrape_attempted_percentage = scrape_attempted_counts[True] / df.shape[0] * 100\n",
    "# else:\n",
    "#     scrape_attempted_percentage = 0\n",
    "    \n",
    "# # If the column is not boolean, you might need to convert it or compare with the string 'True' instead\n",
    "# # Example:\n",
    "# # scrape_attempted_counts = df['scrape_attempted'].value_counts(normalize=True)\n",
    "# # scrape_attempted_percentage = scrape_attempted_counts.get(\"True\", 0) * 100\n",
    "\n",
    "# print(df['scrape_attempted'].unique())\n",
    "\n",
    "# (3) Number of instances with \"not found\" in each column\n",
    "not_found_counts = df.apply(lambda x: x.str.contains('not found', case=False, na=False).sum() if x.dtype == \"object\" else 0).sort_values(ascending=False)\n",
    "\n",
    "# (4) Number of instances with no value in each column\n",
    "no_value_counts = df.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "# (5) Number of malformed rows (more than 3 fields missing)\n",
    "malformed_rows_count = df.isna().sum(axis=1)[df.isna().sum(axis=1) > 3].count()\n",
    "\n",
    "# (6) Number of rows in each category\n",
    "category_counts = df['category'].value_counts()\n",
    "\n",
    "# (7) Number of instances where the URL does not say Grubhub\n",
    "non_grubhub_urls_count = df['url'].apply(lambda x: 'grubhub' not in x.lower()).sum()\n",
    "\n",
    "# Display the results\n",
    "impression_rank_percentiles, ratings_percentiles, scrape_attempted_counts, not_found_counts, no_value_counts, malformed_rows_count, category_counts, non_grubhub_urls_count\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
